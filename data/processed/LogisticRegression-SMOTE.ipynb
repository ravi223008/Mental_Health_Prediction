{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc3e06",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, roc_auc_score, f1_score\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ==== 读取与按不同键合并 ====\n",
    "Xy = pd.read_csv(\"clean_numeric_model.csv\")        # 含 User_ID 与目标列\n",
    "splits = pd.read_csv(\"splits_70_15_15_k5.csv\")     # 含 row_id, split ∈ {train,val,test}\n",
    "\n",
    "# 用 User_ID (左) ↔ row_id (右) 对齐\n",
    "df = Xy.merge(splits[[\"row_id\", \"split\"]], left_on=\"User_ID\", right_on=\"row_id\", how=\"inner\")\n",
    "\n",
    "# ==== 目标列设置（按你们实际情况二选一）====\n",
    "TARGET = \"Severity_ord\"       # 如果你们用的是 severity_level，就改成 \"severity_level\"\n",
    "\n",
    "# 若目标非整数，做编码（0..K-1）\n",
    "if df[TARGET].dtype.kind not in \"iu\":\n",
    "    le = LabelEncoder()\n",
    "    df[TARGET] = le.fit_transform(df[TARGET].astype(str))\n",
    "    print(\"Encoded target classes:\", dict(enumerate(le.classes_)))\n",
    "\n",
    "# ==== 组装特征与标签 ====\n",
    "# 去掉目标、split、以及两个ID列，剩余都是特征\n",
    "drop_cols = {TARGET, \"split\", \"row_id\", \"User_ID\"}\n",
    "feature_cols = [c for c in df.columns if c not in drop_cols]\n",
    "X = df[feature_cols]\n",
    "y = df[TARGET].astype(int)\n",
    "\n",
    "# 划分训练/测试\n",
    "X_train, y_train = X[df[\"split\"] == \"train\"], y[df[\"split\"] == \"train\"]\n",
    "X_test,  y_test  = X[df[\"split\"] == \"test\"],  y[df[\"split\"] == \"test\"]\n",
    "print(f\"Shapes -> X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "\n",
    "# ==== 模型（L2 多项逻辑回归） ====\n",
    "clf = LogisticRegression(\n",
    "    penalty=\"l2\",\n",
    "    solver=\"lbfgs\",            # 支持 multinomial\n",
    "    multi_class=\"multinomial\",\n",
    "    max_iter=1000,\n",
    "    C=1.0,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# ==== 预测与评估 ====\n",
    "y_pred = clf.predict(X_test)\n",
    "y_prob = clf.predict_proba(X_test)\n",
    "\n",
    "print(\"\\n=== Classification report ===\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0, digits=4))\n",
    "\n",
    "macro_f1 = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "macro_auc = np.nan\n",
    "try:\n",
    "    # 多分类宏平均 AUC（OvR）\n",
    "    macro_auc = roc_auc_score(y_test, y_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "except Exception as e:\n",
    "    print(\"[Warn] AUC failed:\", e)\n",
    "\n",
    "print(\"\\n=== Macro metrics ===\")\n",
    "print(f\"Macro-F1       : {macro_f1:.4f}\")\n",
    "print(\"Macro ROC-AUC  :\", \"NaN\" if np.isnan(macro_auc) else f\"{macro_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9840c80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 组装特征与标签（沿用你已有的代码到这里）====\n",
    "drop_cols = {TARGET, \"split\", \"row_id\", \"User_ID\"}\n",
    "feature_cols = [c for c in df.columns if c not in drop_cols]\n",
    "X = df[feature_cols]\n",
    "y = df[TARGET].astype(int)\n",
    "\n",
    "# ===== 按 split 划分（只在 train 上做 SMOTE/拟合）=====\n",
    "X_train, y_train = X[df[\"split\"] == \"train\"], y[df[\"split\"] == \"train\"]\n",
    "X_test,  y_test  = X[df[\"split\"] == \"test\"],  y[df[\"split\"] == \"test\"]\n",
    "print(f\"Shapes -> X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "\n",
    "# ====== SMOTENC 设置 ======\n",
    "# 1) 优先从 smote_config.json 读取 categorical_indices / numeric_indices\n",
    "# 2) 若文件不存在，则按列名后缀自动推断：*_lbl / *_bin 视为类别，其余数值型为数值\n",
    "import json, os\n",
    "from pathlib import Path\n",
    "\n",
    "smote_cfg_path = Path(\"smote_config.json\")\n",
    "if smote_cfg_path.exists():\n",
    "    with open(smote_cfg_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        smote_cfg = json.load(f)\n",
    "    # indices 是基于 feature_cols 顺序的下标\n",
    "    cat_idx = smote_cfg.get(\"categorical_indices\", [])\n",
    "    num_idx = smote_cfg.get(\"numeric_indices\", [])\n",
    "    # 修正: 只保留合法下标，避免越界\n",
    "    cat_idx = [i for i in cat_idx if 0 <= i < len(feature_cols)]\n",
    "    num_idx = [i for i in num_idx if 0 <= i < len(feature_cols)]\n",
    "else:\n",
    "    cat_cols = [c for c in feature_cols if c.endswith(\"_lbl\") or c.endswith(\"_bin\")]\n",
    "    num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "    cat_idx = [feature_cols.index(c) for c in cat_cols]\n",
    "    num_idx = [feature_cols.index(c) for c in num_cols]\n",
    "\n",
    "# 为后续 ColumnTransformer 也保留列名列表\n",
    "cat_cols = [feature_cols[i] for i in cat_idx]\n",
    "num_cols = [feature_cols[i] for i in num_idx]\n",
    "\n",
    "print(f\"[Info] Categorical columns: {len(cat_cols)} -> {cat_cols[:8]}{'...' if len(cat_cols)>8 else ''}\")\n",
    "print(f\"[Info] Numeric columns    : {len(num_cols)} -> {num_cols[:8]}{'...' if len(num_cols)>8 else ''}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5002667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 建 Pipeline：SMOTENC(仅 fit 时在训练集触发) -> 预处理 -> 逻辑回归 ======\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1f3d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# SMOTENC 参数：如 smote_config.json 里有建议就读出来；否则给一套稳妥缺省\n",
    "smote_params = {\n",
    "    \"categorical_features\": cat_idx,\n",
    "    \"sampling_strategy\": \"auto\",   # 可按需要改为 float/字典\n",
    "    \"k_neighbors\": 5,\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "if smote_cfg_path.exists():\n",
    "    # 将已有配置中常见键带过来（若存在）\n",
    "    for k in [\"sampling_strategy\", \"k_neighbors\", \"random_state\"]:\n",
    "        if k in smote_cfg:\n",
    "            smote_params[k] = smote_cfg[k]\n",
    "\n",
    "smote = SMOTENC(**smote_params)\n",
    "\n",
    "# 预处理：类别 -> OneHot，数值 -> StandardScaler（保持均值0方差1，有助于LR收敛）\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols),\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# 逻辑回归：多分类、L2；若仍不平衡，可再加 class_weight=\"balanced\"（与SMOTE可二选一，不建议同时用）\n",
    "clf = LogisticRegression(\n",
    "    penalty=\"l2\",\n",
    "    solver=\"lbfgs\",\n",
    "    multi_class=\"multinomial\",\n",
    "    max_iter=1000,\n",
    "    C=1.0,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipe = ImbPipeline(steps=[\n",
    "    (\"smote\", smote),          # 仅在 fit(X_train, y_train) 时调用 fit_resample\n",
    "    (\"prep\", preprocess),\n",
    "    (\"clf\", clf)\n",
    "])\n",
    "\n",
    "# ====== 训练（只用训练集；不会对测试集过采样）======\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# ====== 预测与评估 ======\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_prob = pipe.predict_proba(X_test)\n",
    "\n",
    "print(\"\\n=== Classification report ===\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0, digits=4))\n",
    "\n",
    "macro_f1 = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "try:\n",
    "    macro_auc = roc_auc_score(y_test, y_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "except Exception as e:\n",
    "    macro_auc = np.nan\n",
    "    print(\"[Warn] AUC failed:\", e)\n",
    "\n",
    "print(\"\\n=== Macro metrics ===\")\n",
    "print(f\"Macro-F1       : {macro_f1:.4f}\")\n",
    "print(\"Macro ROC-AUC  :\", \"NaN\" if np.isnan(macro_auc) else f\"{macro_auc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
