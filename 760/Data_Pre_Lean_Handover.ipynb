{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Data Pre (Lean) — Handover Notes\n\nThis notebook explains what the `Data Pre.py` script does and what it produces. It covers: cleaning, artifacts, 70/15/15 split with train-only K-fold labels, fairness guardrails, and SMOTE preparation.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1) What the script does (high-level)\n- Cleaning & normalization (missing tokens unified; key numerics coerced; text normalized; ordinals/binaries derived; range clipping; dedup).\n- Two cleaned tables: `clean_full.csv` (analysis) and `clean_numeric.csv` (modeling) + `label_mappings.json`.\n- Privacy-safe output: RR3-rounded public table + k-anonymity note.\n- Stratified 70/15/15 split + **train-only** K-fold labels (default 5).\n- Fairness guardrails: `clean_numeric_model.csv`, group representation & missingness gaps in summary, optional `sample_weights.csv`.\n- SMOTE prep (diagnostics only): `smote_config.json`, `imbalance_report.txt`.\n- Run log: `cleaning_summary.txt`.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2) Artifacts and how to use them\n- `clean_full.csv`: EDA/reporting; keeps text & NA.\n- `clean_numeric.csv`: modeling; numeric/_ord/_bin/_lbl; simple imputation.\n- `label_mappings.json`: codebooks for *_lbl.\n- `reports/tables_public/mh_by_gender_rr3.csv`: public share (RR3).\n- `splits_70_15_15_k5.csv`: columns = `row_id`, `split`, `cv_fold` (train only).\n- `clean_numeric_model.csv` & `sample_weights.csv`: fairness-friendly options.\n- `smote_config.json` & `imbalance_report.txt`: for SMOTENC later (training folds only).\n- `cleaning_summary.txt`: one-page summary of all above.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3) Splits & K-fold labels\n- 70/15/15 split stratified by `Mental_Health_Condition` (Yes/No → 1/0).\n- `cv_fold` assigned **only** for training rows (0..K-1), `-1` for val/test.\n- Use CV inside train; use val for early stopping (if needed); evaluate once on test.\n- Any learnable step (scaler/encoder/**SMOTENC**) must be fit inside training folds only.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4) Fairness guardrails (non-intrusive)\n- `clean_numeric_model.csv`: drops direct sensitive columns; optional `*_isna` flags.\n- Summary logs group representation/positivity and missingness gaps; warns on small groups in val/test.\n- `sample_weights.csv`: `w_label`, `w_group`, `w_combo` (optional, not auto-applied).\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5) SMOTE preparation\n- No oversampling in cleaning to avoid leakage; only diagnostics/config.\n- `smote_config.json`: `categorical_indices` (all *_lbl/_bin), `numeric_indices`, and recommended knobs (`sampler`, `sampling_strategy`, `k_neighbors`, `random_state`).\n- `imbalance_report.txt`: train class counts and per-fold counts.\n- In modeling, apply **SMOTENC only on training folds**; never on val/test.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6) Quick checklist\n- Files present: cleaned tables, labels, summary, splits; fairness add-ons; SMOTE prep; public table.\n- Derived columns exist; ranges clipped; splits approx 70/15/15; `cv_fold` only on train.\n- Summary includes fairness notes + SMOTE prep line.\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}