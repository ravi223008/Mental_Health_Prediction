{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMRc1G1sOsBwmZ5clTfJ/LF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"Lj1QKwpBKafi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758355814256,"user_tz":-720,"elapsed":30343,"user":{"displayName":"Ravi Raj","userId":"04166024479811920122"}},"outputId":"c42ded97-d9a4-44e0-8648-c3c15fb3aeea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Replace 'path/to/your/dataset.csv' with the actual path to your file in Google Drive\n","try:\n","    df = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/ML/mental_health_data.csv')\n","    display(df.head())\n","except FileNotFoundError:\n","    print(\"Error: Dataset not found. Please check the path to your file.\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"id":"Y0aUGzisLIoL","executionInfo":{"status":"ok","timestamp":1758355835278,"user_tz":-720,"elapsed":1979,"user":{"displayName":"Ravi Raj","userId":"04166024479811920122"}},"outputId":"828e9566-ebc3-4a2a-9e53-974c8e0a03e4"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["   User_ID  Age             Gender   Occupation    Country  \\\n","0        1   36               Male    Education  Australia   \n","1        2   48               Male  Engineering      Other   \n","2        3   18  Prefer not to say        Sales      India   \n","3        4   30         Non-binary  Engineering  Australia   \n","4        5   58               Male           IT        USA   \n","\n","  Mental_Health_Condition Severity Consultation_History Stress_Level  \\\n","0                     Yes      NaN                  Yes          Low   \n","1                      No      Low                   No          Low   \n","2                      No      NaN                  Yes       Medium   \n","3                      No   Medium                   No          Low   \n","4                     Yes      NaN                  Yes         High   \n","\n","   Sleep_Hours  Work_Hours  Physical_Activity_Hours  Social_Media_Usage  \\\n","0          7.6          46                        8                 2.2   \n","1          6.8          74                        2                 3.4   \n","2          7.1          77                        9                 5.9   \n","3          6.9          57                        4                 5.4   \n","4          4.7          45                       10                 3.3   \n","\n","  Diet_Quality   Smoking_Habit Alcohol_Consumption Medication_Usage  \n","0      Healthy  Regular Smoker     Regular Drinker              Yes  \n","1    Unhealthy    Heavy Smoker      Social Drinker               No  \n","2      Healthy    Heavy Smoker      Social Drinker               No  \n","3      Average  Regular Smoker     Regular Drinker               No  \n","4    Unhealthy  Regular Smoker         Non-Drinker              Yes  "],"text/html":["\n","  <div id=\"df-8960ef54-eb1f-427a-84b7-1016f7bfac23\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User_ID</th>\n","      <th>Age</th>\n","      <th>Gender</th>\n","      <th>Occupation</th>\n","      <th>Country</th>\n","      <th>Mental_Health_Condition</th>\n","      <th>Severity</th>\n","      <th>Consultation_History</th>\n","      <th>Stress_Level</th>\n","      <th>Sleep_Hours</th>\n","      <th>Work_Hours</th>\n","      <th>Physical_Activity_Hours</th>\n","      <th>Social_Media_Usage</th>\n","      <th>Diet_Quality</th>\n","      <th>Smoking_Habit</th>\n","      <th>Alcohol_Consumption</th>\n","      <th>Medication_Usage</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>36</td>\n","      <td>Male</td>\n","      <td>Education</td>\n","      <td>Australia</td>\n","      <td>Yes</td>\n","      <td>NaN</td>\n","      <td>Yes</td>\n","      <td>Low</td>\n","      <td>7.6</td>\n","      <td>46</td>\n","      <td>8</td>\n","      <td>2.2</td>\n","      <td>Healthy</td>\n","      <td>Regular Smoker</td>\n","      <td>Regular Drinker</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>48</td>\n","      <td>Male</td>\n","      <td>Engineering</td>\n","      <td>Other</td>\n","      <td>No</td>\n","      <td>Low</td>\n","      <td>No</td>\n","      <td>Low</td>\n","      <td>6.8</td>\n","      <td>74</td>\n","      <td>2</td>\n","      <td>3.4</td>\n","      <td>Unhealthy</td>\n","      <td>Heavy Smoker</td>\n","      <td>Social Drinker</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>18</td>\n","      <td>Prefer not to say</td>\n","      <td>Sales</td>\n","      <td>India</td>\n","      <td>No</td>\n","      <td>NaN</td>\n","      <td>Yes</td>\n","      <td>Medium</td>\n","      <td>7.1</td>\n","      <td>77</td>\n","      <td>9</td>\n","      <td>5.9</td>\n","      <td>Healthy</td>\n","      <td>Heavy Smoker</td>\n","      <td>Social Drinker</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>30</td>\n","      <td>Non-binary</td>\n","      <td>Engineering</td>\n","      <td>Australia</td>\n","      <td>No</td>\n","      <td>Medium</td>\n","      <td>No</td>\n","      <td>Low</td>\n","      <td>6.9</td>\n","      <td>57</td>\n","      <td>4</td>\n","      <td>5.4</td>\n","      <td>Average</td>\n","      <td>Regular Smoker</td>\n","      <td>Regular Drinker</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>58</td>\n","      <td>Male</td>\n","      <td>IT</td>\n","      <td>USA</td>\n","      <td>Yes</td>\n","      <td>NaN</td>\n","      <td>Yes</td>\n","      <td>High</td>\n","      <td>4.7</td>\n","      <td>45</td>\n","      <td>10</td>\n","      <td>3.3</td>\n","      <td>Unhealthy</td>\n","      <td>Regular Smoker</td>\n","      <td>Non-Drinker</td>\n","      <td>Yes</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8960ef54-eb1f-427a-84b7-1016f7bfac23')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8960ef54-eb1f-427a-84b7-1016f7bfac23 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8960ef54-eb1f-427a-84b7-1016f7bfac23');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-c5f22862-c592-4d50-aa8c-11144bc4d4b3\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c5f22862-c592-4d50-aa8c-11144bc4d4b3')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-c5f22862-c592-4d50-aa8c-11144bc4d4b3 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"    print(f\\\"An error occurred: {e}\\\")\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"User_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 18,\n        \"max\": 58,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          48,\n          58,\n          18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Male\",\n          \"Prefer not to say\",\n          \"Non-binary\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Occupation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Engineering\",\n          \"IT\",\n          \"Education\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Country\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Other\",\n          \"USA\",\n          \"Australia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mental_Health_Condition\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Severity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Medium\",\n          \"Low\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Consultation_History\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stress_Level\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Low\",\n          \"Medium\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sleep_Hours\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1166915420114902,\n        \"min\": 4.7,\n        \"max\": 7.6,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          6.8,\n          4.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Work_Hours\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 45,\n        \"max\": 77,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          74,\n          45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Physical_Activity_Hours\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 2,\n        \"max\": 10,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Social_Media_Usage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5533834040570926,\n        \"min\": 2.2,\n        \"max\": 5.9,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.4,\n          3.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Diet_Quality\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Healthy\",\n          \"Unhealthy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Smoking_Habit\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Heavy Smoker\",\n          \"Regular Smoker\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Alcohol_Consumption\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Regular Drinker\",\n          \"Social Drinker\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Medication_Usage\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"code","source":["#Data Cleaning\n","# ----------------------------\n","# Step 1: Drop duplicates\n","# ----------------------------\n","df = df.drop_duplicates()\n","\n","# ----------------------------\n","# Step 2: Drop useless column\n","# ----------------------------\n","df = df.drop(columns=[\"Unnamed: 0\"], errors=\"ignore\")\n","#df\n","\n","# ----------------------------\n","# Step 3: Handle missing values\n","# ----------------------------\n","# Option A: Fill missing values in 'Severity' with \"Unknown\"\n","df[\"Severity\"] = df[\"Severity\"].fillna(\"Unknown\")\n","#df\n","\n","# ----------------------------\n","# Save cleaned dataset in Google Drive path\n","# ----------------------------\n","save_path = \"/content/drive/MyDrive/ColabNotebooks/ML/ML_dataset_cleaned_without_one_hot_encoding.csv\"\n","df.to_csv(save_path, index=False)\n","print(\"‚úÖ Dataset cleaned and saved as ML_dataset_cleaned.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mlJkc6iVLSH3","executionInfo":{"status":"ok","timestamp":1758355978070,"user_tz":-720,"elapsed":530,"user":{"displayName":"Ravi Raj","userId":"04166024479811920122"}},"outputId":"5da56ab0-baf8-41e0-e6a9-1afa94ce3690"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Dataset cleaned and saved as ML_dataset_cleaned.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","\n","# ----------------------------\n","# Load and Clean the Dataset\n","# ----------------------------\n","# Load your dataset from the path before it was encoded\n","try:\n","    df = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/ML/ML_dataset_cleaned_without_one_hot_encoding.csv\")\n","except FileNotFoundError:\n","    print(\"Please make sure 'ML_dataset_cleaned_without_one_hot_encoding.csv' is in the correct path.\")\n","    # Creating a placeholder if the file is not found\n","    data = {'User_ID': [1, 2, 3, 4], 'Age': [36, 48, 18, 30], 'Gender': ['Male', 'Male', 'Prefer not to say', 'Non-binary'],\n","            'Occupation': ['Education', 'Engineering', 'Sales', 'Engineering'], 'Severity': ['Unknown', 'Low', 'Unknown', 'Medium']}\n","    df = pd.DataFrame(data)\n","\n","# Basic cleaning steps\n","df = df.drop_duplicates()\n","df = df.drop(columns=[\"Unnamed: 0\"], errors=\"ignore\")\n","df[\"Severity\"] = df[\"Severity\"].fillna(\"Unknown\")\n","\n","\n","# ----------------------------\n","# Step 4 (Corrected): Separate Target from Features ‚ú®\n","# ----------------------------\n","# The 'Severity' column is what we want to predict (our target, y)\n","y = df['Severity']\n","\n","# The rest of the data, excluding identifiers like User_ID, are our features (X)\n","X = df.drop(columns=['Severity', 'User_ID'], errors='ignore')\n","\n","\n","# ----------------------------\n","# Step 5 (New): Encode Target and Features Separately ‚ú®\n","# ----------------------------\n","# A. Encode the target variable 'y' using LabelEncoder\n","# This converts labels like 'Low', 'Medium' into numbers (0, 1, 2...) in a single column\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","# B. One-hot encode the features 'X'\n","X_encoded = pd.get_dummies(X, drop_first=True)\n","\n","\n","# --- Display Results to Verify ---\n","print(\"--- Preview of the Correctly Encoded Features (X) ---\")\n","print(X_encoded.head())\n","\n","print(\"\\n--- Preview of the Correctly Encoded Target (y) ---\")\n","print(\"Original labels:\", y.head().values)\n","print(\"Encoded labels: \", y_encoded[:5]) # Show first 5 encoded numbers\n","\n","# Show the mapping from text to number\n","print(\"\\n--- Target Label Mapping ---\")\n","for i, class_name in enumerate(label_encoder.classes_):\n","    print(f\"'{class_name}'  ->  {i}\")\n","\n","\n","# ----------------------------\n","# Save the Processed Data\n","# ----------------------------\n","# It's best practice to save your processed features and target separately\n","X_encoded.to_csv(\"/content/drive/MyDrive/ColabNotebooks/ML/features_processed.csv\", index=False)\n","pd.Series(y_encoded, name=\"target\").to_csv(\"/content/drive/MyDrive/ColabNotebooks/ML/target_processed.csv\", index=False)\n","\n","print(\"\\n‚úÖ Processed features and target saved to 'features_processed.csv' and 'target_processed.csv'\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9QO8vk70NA33","executionInfo":{"status":"ok","timestamp":1758357124693,"user_tz":-720,"elapsed":1513,"user":{"displayName":"Ravi Raj","userId":"04166024479811920122"}},"outputId":"4a80e56e-5a46-4099-e9cb-129d0f37c3c9"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Preview of the Correctly Encoded Features (X) ---\n","   Age  Sleep_Hours  Work_Hours  Physical_Activity_Hours  Social_Media_Usage  \\\n","0   36          7.6          46                        8                 2.2   \n","1   48          6.8          74                        2                 3.4   \n","2   18          7.1          77                        9                 5.9   \n","3   30          6.9          57                        4                 5.4   \n","4   58          4.7          45                       10                 3.3   \n","\n","   Gender_Male  Gender_Non-binary  Gender_Prefer not to say  \\\n","0         True              False                     False   \n","1         True              False                     False   \n","2        False              False                      True   \n","3        False               True                     False   \n","4         True              False                     False   \n","\n","   Occupation_Engineering  Occupation_Finance  ...  Stress_Level_Medium  \\\n","0                   False               False  ...                False   \n","1                    True               False  ...                False   \n","2                   False               False  ...                 True   \n","3                    True               False  ...                False   \n","4                   False               False  ...                False   \n","\n","   Diet_Quality_Healthy  Diet_Quality_Unhealthy  Smoking_Habit_Non-Smoker  \\\n","0                  True                   False                     False   \n","1                 False                    True                     False   \n","2                  True                   False                     False   \n","3                 False                   False                     False   \n","4                 False                    True                     False   \n","\n","   Smoking_Habit_Occasional Smoker  Smoking_Habit_Regular Smoker  \\\n","0                            False                          True   \n","1                            False                         False   \n","2                            False                         False   \n","3                            False                          True   \n","4                            False                          True   \n","\n","   Alcohol_Consumption_Non-Drinker  Alcohol_Consumption_Regular Drinker  \\\n","0                            False                                 True   \n","1                            False                                False   \n","2                            False                                False   \n","3                            False                                 True   \n","4                             True                                False   \n","\n","   Alcohol_Consumption_Social Drinker  Medication_Usage_Yes  \n","0                               False                  True  \n","1                                True                 False  \n","2                                True                 False  \n","3                               False                 False  \n","4                               False                  True  \n","\n","[5 rows x 33 columns]\n","\n","--- Preview of the Correctly Encoded Target (y) ---\n","Original labels: ['Unknown' 'Low' 'Unknown' 'Medium' 'Unknown']\n","Encoded labels:  [3 1 3 2 3]\n","\n","--- Target Label Mapping ---\n","'High'  ->  0\n","'Low'  ->  1\n","'Medium'  ->  2\n","'Unknown'  ->  3\n","\n","‚úÖ Processed features and target saved to 'features_processed.csv' and 'target_processed.csv'\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import StratifiedKFold, cross_val_score\n","from sklearn.preprocessing import StandardScaler\n","import pandas as pd\n","import numpy as np\n","import xgboost as xgb\n","\n","# --- 1. LOAD YOUR PROCESSED DATA ---\n","# Let's assume you're running this in a new session and need to load the files you just saved.\n","try:\n","    X_processed = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/ML/features_processed.csv\")\n","    y_processed = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/ML/target_processed.csv\").squeeze(\"columns\") # .squeeze converts it to a Series\n","except FileNotFoundError:\n","    print(\"Processed files not found. Please ensure they are in the correct directory.\")\n","    # You would handle this error appropriately in a real script\n","    exit()\n","\n","# --- 2. SCALE THE FEATURES ---\n","# Initialize the scaler\n","scaler = StandardScaler()\n","\n","# Fit the scaler to the feature data and transform it\n","X_scaled = scaler.fit_transform(X_processed)\n","\n","print(\"--- Features Scaled ---\")\n","print(\"The data type of X_scaled is:\", type(X_scaled))\n","print(\"Shape of X_scaled:\", X_scaled.shape)\n","\n","\n","# --- 3. SPLIT THE DATA FOR TRAINING AND TESTING ---XGBoost with 5-Fold Cross-Validation----\n","# This is the final preparation step!\n","# --- INITIALIZE THE XGBOOST CLASSIFIER AND K-FOLD ---\n","# We determine the number of classes directly from our target variable\n","num_classes = y_processed.nunique()\n","\n","# Initialize the XGBoost model for multi-class classification\n","model_xgb = xgb.XGBClassifier(\n","    objective='multi:softmax',  # Specifies the learning task\n","    num_class=num_classes,      # Number of unique classes to predict\n","    seed=42                     # for reproducibility\n",")\n","\n","# Set up the 5-fold cross-validation strategy\n","# StratifiedKFold is best for classification to preserve the percentage of samples for each class.\n","kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","\n","# --- RUN THE CROSS-VALIDATION ---\n","print(\"üöÄ Running 5-Fold Cross-Validation with XGBoost...\")\n","scores = cross_val_score(\n","    model_xgb,\n","    X_scaled,\n","    y_processed,\n","    cv=kfold,\n","    scoring='accuracy' # You can change this to other metrics like 'f1_macro'\n",")\n","\n","# --- PRINT THE RESULTS ---\n","print(\"\\n--- Cross-Validation Results ---\")\n","print(f\"Fold Accuracies: {np.round(scores, 4)}\")\n","print(f\"Average Accuracy (Mean): {scores.mean():.4f}\")\n","print(f\"Accuracy Standard Deviation: {scores.std():.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ps-M_zI3P_XE","executionInfo":{"status":"ok","timestamp":1758357442029,"user_tz":-720,"elapsed":18019,"user":{"displayName":"Ravi Raj","userId":"04166024479811920122"}},"outputId":"635804d2-463d-4a63-a25d-f59b28ff2b45"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Features Scaled ---\n","The data type of X_scaled is: <class 'numpy.ndarray'>\n","Shape of X_scaled: (50000, 33)\n","üöÄ Running 5-Fold Cross-Validation with XGBoost...\n","\n","--- Cross-Validation Results ---\n","Fold Accuracies: [0.4883 0.4869 0.4861 0.4847 0.4867]\n","Average Accuracy (Mean): 0.4865\n","Accuracy Standard Deviation: 0.0012\n"]}]},{"cell_type":"code","source":["#Train and Evaluate the Final Model\n","#------------------------------------\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# --- SPLIT DATA (we repeat this step to ensure we have the variables) ---\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_scaled, y_processed, test_size=0.2, random_state=42, stratify=y_processed\n",")\n","\n","# --- TRAIN THE FINAL XGBOOST MODEL ---\n","print(\"\\nüí™ Training the final XGBoost model on the full training set...\")\n","final_model = xgb.XGBClassifier(\n","    objective='multi:softmax',\n","    num_class=num_classes,\n","    seed=42\n",")\n","final_model.fit(X_train, y_train)\n","print(\"‚úÖ Training complete.\")\n","\n","# --- MAKE PREDICTIONS AND EVALUATE ---\n","print(\"\\nüîç Evaluating the model on the unseen test set...\")\n","y_pred = final_model.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"\\nTest Set Accuracy: {accuracy:.4f}\")\n","\n","# Display a detailed classification report\n","# Note: You need the original label encoder to see the class names\n","# Let's create it again for clarity\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","# Assuming the classes are ['High', 'Low', 'Medium', 'Unknown'] in the order they were encoded\n","le.fit(['High', 'Low', 'Medium', 'Unknown'])\n","\n","\n","print(\"\\n--- Classification Report ---\")\n","print(classification_report(y_test, y_pred, target_names=le.classes_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hugDZJNURlEk","executionInfo":{"status":"ok","timestamp":1758357531972,"user_tz":-720,"elapsed":2560,"user":{"displayName":"Ravi Raj","userId":"04166024479811920122"}},"outputId":"2a981d5b-d0b7-42d3-cf2c-e8737c0a01f4"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üí™ Training the final XGBoost model on the full training set...\n","‚úÖ Training complete.\n","\n","üîç Evaluating the model on the unseen test set...\n","\n","Test Set Accuracy: 0.4836\n","\n","--- Classification Report ---\n","              precision    recall  f1-score   support\n","\n","        High       0.15      0.01      0.02      1660\n","         Low       0.12      0.01      0.02      1652\n","      Medium       0.15      0.01      0.02      1687\n","     Unknown       0.50      0.96      0.66      5001\n","\n","    accuracy                           0.48     10000\n","   macro avg       0.23      0.25      0.18     10000\n","weighted avg       0.32      0.48      0.34     10000\n","\n"]}]},{"cell_type":"code","source":["#Model is facing a classic and very common machine learning problem: severe class imbalance.\n","#Next Step: Handle the Class Imbalance with SMOTE\n","import pandas as pd\n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.metrics import classification_report, accuracy_score, roc_auc_score # ‚ú® Import roc_auc_score\n","from imblearn.over_sampling import SMOTE\n","\n","# --- 1. LOAD AND PREPARE DATA (As before) ---\n","X_processed = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/ML/features_processed.csv\")\n","y_processed = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/ML/target_processed.csv\").squeeze(\"columns\")\n","\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X_processed)\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_scaled, y_processed, test_size=0.2, random_state=42, stratify=y_processed\n",")\n","\n","\n","# --- 2. APPLY SMOTE TO THE TRAINING DATA ---\n","print(\"Class distribution before SMOTE:\", pd.Series(y_train).value_counts().sort_index())\n","\n","smote = SMOTE(random_state=42)\n","X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n","\n","print(\"\\nClass distribution after SMOTE:\", pd.Series(y_train_resampled).value_counts().sort_index())\n","\n","\n","# --- 3. TRAIN XGBOOST ON THE NEW, BALANCED DATA ---\n","print(\"\\nüí™ Training XGBoost model on the resampled data...\")\n","num_classes = y_processed.nunique()\n","\n","balanced_model = xgb.XGBClassifier(\n","    objective='multi:softmax',\n","    num_class=num_classes,\n","    seed=42\n",")\n","\n","balanced_model.fit(X_train_resampled, y_train_resampled)\n","print(\"‚úÖ Training complete.\")\n","\n","\n","# --- 4. EVALUATE THE NEW BALANCED MODEL ---\n","print(\"\\nüîç Evaluating the new model on the original, unseen test set...\")\n","y_pred_balanced = balanced_model.predict(X_test)\n","y_pred_proba_balanced = balanced_model.predict_proba(X_test) # ‚ú® Get class probabilities for AUC\n","\n","# --- Calculate Metrics ---\n","accuracy = accuracy_score(y_test, y_pred_balanced)\n","\n","# ‚ú® Calculate Macro AUC score\n","macro_auc = roc_auc_score(\n","    y_test,\n","    y_pred_proba_balanced,\n","    multi_class='ovr', # One-vs-Rest strategy\n","    average='macro'\n",")\n","\n","print(f\"\\nTest Set Accuracy (after SMOTE): {accuracy:.4f}\")\n","print(f\"Test Set Macro AUC (after SMOTE): {macro_auc:.4f}\") # ‚ú® Print the new metric\n","\n","# You need the label encoder again to see the class names\n","le = LabelEncoder()\n","le.fit(['High', 'Low', 'Medium', 'Unknown'])\n","\n","print(\"\\n--- Classification Report (after SMOTE) ---\")\n","print(classification_report(y_test, y_pred_balanced, target_names=le.classes_))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WagtFlTgTb-F","executionInfo":{"status":"ok","timestamp":1758358368046,"user_tz":-720,"elapsed":22183,"user":{"displayName":"Ravi Raj","userId":"04166024479811920122"}},"outputId":"a5388cba-7d53-445a-eb0b-bcc12d2201ac"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Class distribution before SMOTE: target\n","0     6641\n","1     6609\n","2     6749\n","3    20001\n","Name: count, dtype: int64\n","\n","Class distribution after SMOTE: target\n","0    20001\n","1    20001\n","2    20001\n","3    20001\n","Name: count, dtype: int64\n","\n","üí™ Training XGBoost model on the resampled data...\n","‚úÖ Training complete.\n","\n","üîç Evaluating the new model on the original, unseen test set...\n","\n","Test Set Accuracy (after SMOTE): 0.4902\n","Test Set Macro AUC (after SMOTE): 0.5007\n","\n","--- Classification Report (after SMOTE) ---\n","              precision    recall  f1-score   support\n","\n","        High       0.14      0.01      0.01      1660\n","         Low       0.15      0.01      0.02      1652\n","      Medium       0.17      0.01      0.02      1687\n","     Unknown       0.50      0.97      0.66      5001\n","\n","    accuracy                           0.49     10000\n","   macro avg       0.24      0.25      0.18     10000\n","weighted avg       0.33      0.49      0.34     10000\n","\n"]}]},{"cell_type":"code","source":["!pip install tabulate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"opBiCKsaU2P9","executionInfo":{"status":"ok","timestamp":1758358384730,"user_tz":-720,"elapsed":8938,"user":{"displayName":"Ravi Raj","userId":"04166024479811920122"}},"outputId":"42f03137-98cd-49fb-e167-717f949099ec"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (0.9.0)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, f1_score # ‚ú® Import f1_score\n","from imblearn.over_sampling import SMOTE\n","from tabulate import tabulate # ‚ú® Import tabulate\n","\n","# --- 1. LOAD AND PREPARE DATA ---\n","X_processed = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/ML/features_processed.csv\")\n","y_processed = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/ML/target_processed.csv\").squeeze(\"columns\")\n","\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X_processed)\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_scaled, y_processed, test_size=0.2, random_state=42, stratify=y_processed\n",")\n","\n","# --- 2. APPLY SMOTE ---\n","smote = SMOTE(random_state=42)\n","X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n","\n","# --- 3. TRAIN XGBOOST ---\n","print(\"üí™ Training XGBoost model on the resampled data...\")\n","balanced_model = xgb.XGBClassifier(\n","    objective='multi:softmax',\n","    num_class=y_processed.nunique(),\n","    seed=42\n",")\n","balanced_model.fit(X_train_resampled, y_train_resampled)\n","print(\"‚úÖ Training complete.\")\n","\n","# --- 4. EVALUATE THE MODEL ---\n","print(\"\\nüîç Evaluating the model...\")\n","y_pred = balanced_model.predict(X_test)\n","y_pred_proba = balanced_model.predict_proba(X_test)\n","\n","# --- Calculate All Metrics ---\n","accuracy = accuracy_score(y_test, y_pred)\n","macro_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='macro')\n","macro_f1 = f1_score(y_test, y_pred, average='macro') # ‚ú® Calculate Macro F1-Score\n","\n","# --- 5. DISPLAY RESULTS IN A TABLE ‚ú® ---\n","# Prepare the data for the table\n","table_data = [\n","    [\"Accuracy\", f\"{accuracy * 100:.2f} %\"],\n","    [\"Macro AUC\", f\"{macro_auc * 100:.2f} %\"],\n","    [\"Macro F1-Score\", f\"{macro_f1 * 100:.2f} %\"]\n","]\n","\n","# Create the table header\n","headers = [\"XGBoost\", \"\"] # Using model name as header\n","\n","# Print the formatted table\n","print(\"\\n\" + \"=\"*40)\n","print(\"          MODEL EVALUATION SUMMARY\")\n","print(\"=\"*40)\n","print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n","print(\"=\"*40 + \"\\n\")\n","\n","\n","# --- (Optional) Print the detailed classification report as before ---\n","le = LabelEncoder()\n","le.fit(['High', 'Low', 'Medium', 'Unknown'])\n","print(\"\\n--- Detailed Classification Report ---\")\n","print(classification_report(y_test, y_pred, target_names=le.classes_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QEOJJmtcUnKI","executionInfo":{"status":"ok","timestamp":1758358420060,"user_tz":-720,"elapsed":27711,"user":{"displayName":"Ravi Raj","userId":"04166024479811920122"}},"outputId":"c5e23382-8803-4362-af79-8b53b7beb9c6"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["üí™ Training XGBoost model on the resampled data...\n","‚úÖ Training complete.\n","\n","üîç Evaluating the model...\n","\n","========================================\n","          MODEL EVALUATION SUMMARY\n","========================================\n","+----------------+---------+\n","| XGBoost        |         |\n","+================+=========+\n","| Accuracy       | 49.02 % |\n","+----------------+---------+\n","| Macro AUC      | 50.07 % |\n","+----------------+---------+\n","| Macro F1-Score | 17.88 % |\n","+----------------+---------+\n","========================================\n","\n","\n","--- Detailed Classification Report ---\n","              precision    recall  f1-score   support\n","\n","        High       0.14      0.01      0.01      1660\n","         Low       0.15      0.01      0.02      1652\n","      Medium       0.17      0.01      0.02      1687\n","     Unknown       0.50      0.97      0.66      5001\n","\n","    accuracy                           0.49     10000\n","   macro avg       0.24      0.25      0.18     10000\n","weighted avg       0.33      0.49      0.34     10000\n","\n"]}]},{"cell_type":"code","source":["#Updated Pipeline: Removing \"Unknown\" and Retraining\n","\n","import pandas as pd\n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, f1_score\n","from imblearn.over_sampling import SMOTE\n","from tabulate import tabulate\n","\n","# --- 1. LOAD AND PREPARE DATA ---\n","# Start with the original cleaned file\n","df = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/ML/ML_dataset_cleaned_without_one_hot_encoding.csv\")\n","\n","# ‚ú® --- CRUCIAL NEW STEP: REMOVE THE 'UNKNOWN' CLASS --- ‚ú®\n","print(f\"Original dataset shape: {df.shape}\")\n","df = df[df['Severity'] != 'Unknown']\n","print(f\"Dataset shape after removing 'Unknown' class: {df.shape}\\n\")\n","\n","# --- 2. SEPARATE AND ENCODE ---\n","# Separate features (X) and target (y)\n","y = df['Severity']\n","X = df.drop(columns=['Severity', 'User_ID'], errors='ignore')\n","\n","# Encode the new 3-class target variable\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","# One-hot encode the features\n","X_encoded = pd.get_dummies(X, drop_first=True)\n","\n","\n","# --- 3. SCALE AND SPLIT ---\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X_encoded)\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",")\n","\n","\n","# --- 4. APPLY SMOTE ---\n","# SMOTE is still useful as the 3 classes might not be perfectly balanced\n","print(\"Class distribution before SMOTE:\", pd.Series(y_train).value_counts().sort_index())\n","smote = SMOTE(random_state=42)\n","X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n","print(\"Class distribution after SMOTE:\", pd.Series(y_train_resampled).value_counts().sort_index())\n","\n","\n","# --- 5. TRAIN FINAL XGBOOST MODEL ---\n","print(\"\\nüí™ Training XGBoost model on the filtered, balanced data...\")\n","# The number of classes is now 3\n","final_model = xgb.XGBClassifier(\n","    objective='multi:softmax',\n","    num_class=len(label_encoder.classes_),\n","    seed=42\n",")\n","final_model.fit(X_train_resampled, y_train_resampled)\n","print(\"‚úÖ Training complete.\")\n","\n","\n","# --- 6. EVALUATE THE NEW MODEL ---\n","print(\"\\nüîç Evaluating the new 3-class model...\")\n","y_pred = final_model.predict(X_test)\n","y_pred_proba = final_model.predict_proba(X_test)\n","\n","# --- Calculate Metrics ---\n","accuracy = accuracy_score(y_test, y_pred)\n","macro_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='macro')\n","macro_f1 = f1_score(y_test, y_pred, average='macro')\n","\n","# --- Display Results Table ---\n","table_data = [\n","    [\"Accuracy\", f\"{accuracy * 100:.2f} %\"],\n","    [\"Macro AUC\", f\"{macro_auc * 100:.2f} %\"],\n","    [\"Macro F1-Score\", f\"{macro_f1 * 100:.2f} %\"]\n","]\n","headers = [\"XGBoost (3-Class)\", \"\"]\n","print(\"\\n\" + tabulate(table_data, headers=headers, tablefmt=\"grid\") + \"\\n\")\n","\n","# --- Display Detailed Report ---\n","print(\"\\n--- Detailed Classification Report (3-Class Model) ---\")\n","print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W_55qLnlWRxZ","executionInfo":{"status":"ok","timestamp":1758358777312,"user_tz":-720,"elapsed":2531,"user":{"displayName":"Ravi Raj","userId":"04166024479811920122"}},"outputId":"e24a9a55-7d0e-4676-e20a-875d21251dfb"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Original dataset shape: (50000, 17)\n","Dataset shape after removing 'Unknown' class: (24998, 17)\n","\n","Class distribution before SMOTE: 0    6641\n","1    6609\n","2    6748\n","Name: count, dtype: int64\n","Class distribution after SMOTE: 0    6748\n","1    6748\n","2    6748\n","Name: count, dtype: int64\n","\n","üí™ Training XGBoost model on the filtered, balanced data...\n","‚úÖ Training complete.\n","\n","üîç Evaluating the new 3-class model...\n","\n","+---------------------+---------+\n","| XGBoost (3-Class)   |         |\n","+=====================+=========+\n","| Accuracy            | 32.56 % |\n","+---------------------+---------+\n","| Macro AUC           | 49.59 % |\n","+---------------------+---------+\n","| Macro F1-Score      | 32.54 % |\n","+---------------------+---------+\n","\n","\n","--- Detailed Classification Report (3-Class Model) ---\n","              precision    recall  f1-score   support\n","\n","        High       0.32      0.31      0.31      1660\n","         Low       0.32      0.32      0.32      1652\n","      Medium       0.34      0.35      0.34      1688\n","\n","    accuracy                           0.33      5000\n","   macro avg       0.33      0.33      0.33      5000\n","weighted avg       0.33      0.33      0.33      5000\n","\n"]}]}]}